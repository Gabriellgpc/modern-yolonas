{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tune YOLO-NAS on a Roboflow Dataset\n",
        "\n",
        "This notebook demonstrates how to fine-tune YOLO-NAS S on a Roboflow dataset using PyTorch Lightning, then evaluate and visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Make sure you have run `01_explore_dataset.ipynb` first to download the dataset from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config + setup\n",
        "from modern_yolonas.data import load_dataset_config\n",
        "\n",
        "cfg = load_dataset_config(\"./hardhat-dataset/data.yaml\")\n",
        "print(f\"Training on {cfg.num_classes} classes: {cfg.class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune with Lightning\n",
        "import torch\n",
        "import lightning as L\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "from modern_yolonas import yolo_nas_s\n",
        "from modern_yolonas.data import YOLODetectionDataset\n",
        "from modern_yolonas.data.transforms import (\n",
        "    Compose, HSVAugment, HorizontalFlip, LetterboxResize, Normalize,\n",
        ")\n",
        "from modern_yolonas.training import (\n",
        "    YoloNASLightningModule, EMACallback, DetectionDataModule,\n",
        ")\n",
        "\n",
        "model = yolo_nas_s(pretrained=True, num_classes=cfg.num_classes)\n",
        "print(f\"Model created: YOLO-NAS S with {cfg.num_classes} classes\")\n",
        "\n",
        "train_transforms = Compose([\n",
        "    HSVAugment(), HorizontalFlip(p=0.5), LetterboxResize(target_size=640), Normalize(),\n",
        "])\n",
        "val_transforms = Compose([LetterboxResize(target_size=640), Normalize()])\n",
        "\n",
        "train_ds = YOLODetectionDataset(root=cfg.root, split=cfg.train_split, transforms=train_transforms)\n",
        "val_ds = YOLODetectionDataset(root=cfg.root, split=cfg.val_split, transforms=val_transforms)\n",
        "\n",
        "lit_model = YoloNASLightningModule(model=model, num_classes=cfg.num_classes, lr=2e-4, warmup_steps=100)\n",
        "data_module = DetectionDataModule(train_dataset=train_ds, val_dataset=val_ds, batch_size=8, num_workers=2)\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=15, accelerator=\"auto\", precision=\"16-mixed\",\n",
        "    callbacks=[EMACallback(), ModelCheckpoint(dirpath=\"runs/hardhat\", save_last=True)],\n",
        "    default_root_dir=\"runs/hardhat\",\n",
        ")\n",
        "trainer.fit(lit_model, datamodule=data_module)\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate & Visualize\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from modern_yolonas import Detector\n",
        "from modern_yolonas.training import extract_model_state_dict\n",
        "\n",
        "best_ckpt = \"runs/hardhat/last.ckpt\"\n",
        "sd = extract_model_state_dict(best_ckpt)\n",
        "model.load_state_dict(sd)\n",
        "model.eval()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "detector = Detector(model=model, device=device, conf_threshold=0.25, iou_threshold=0.45, retain_image=True)\n",
        "\n",
        "val_images = sorted((cfg.root / \"images\" / cfg.val_split).glob(\"*.*\"))[:8]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "class_detection_counts = Counter()\n",
        "\n",
        "for ax, img_path in zip(axes.flat, val_images):\n",
        "    detection = detector.detect_image(str(img_path))\n",
        "    vis = detection.visualize(class_names=cfg.class_names)\n",
        "    ax.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
        "    ax.set_title(f\"{len(detection.boxes)} detections\")\n",
        "    ax.axis(\"off\")\n",
        "    for cls_id in detection.class_ids:\n",
        "        name = cfg.class_names[int(cls_id)] if int(cls_id) < len(cfg.class_names) else f\"class_{int(cls_id)}\"\n",
        "        class_detection_counts[name] += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDetection counts per class:\")\n",
        "for name, count in class_detection_counts.most_common():\n",
        "    print(f\"  {name}: {count}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
