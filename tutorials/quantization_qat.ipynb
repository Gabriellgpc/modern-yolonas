{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization-Aware Training (QAT)\n",
        "\n",
        "This tutorial demonstrates how to fine-tune a YOLO-NAS model with fake-quantization nodes for higher INT8 accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "You need a trained checkpoint and training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import lightning as L\n",
        "from pathlib import Path\n",
        "from modern_yolonas import yolo_nas_s\n",
        "from modern_yolonas.data import YOLODetectionDataset, load_dataset_config\n",
        "from modern_yolonas.data.transforms import Compose, HSVAugment, HorizontalFlip, LetterboxResize, Normalize\n",
        "from modern_yolonas.training import (\n",
        "    YoloNASLightningModule, QATCallback, DetectionDataModule, extract_model_state_dict,\n",
        ")\n",
        "from modern_yolonas.quantization import prepare_model_qat, convert_quantized, export_quantized_onnx\n",
        "\n",
        "# Load trained model\n",
        "model = yolo_nas_s(pretrained=True)  # or load from checkpoint\n",
        "# sd = extract_model_state_dict(\"runs/hardhat/last.ckpt\")\n",
        "# model.load_state_dict(sd)\n",
        "\n",
        "# Prepare for QAT (inserts fake-quant nodes)\n",
        "qat_model = prepare_model_qat(model)\n",
        "print(\"QAT model prepared with fake-quantization nodes\")\n",
        "\n",
        "# Setup data\n",
        "# cfg = load_dataset_config(\"path/to/data.yaml\")\n",
        "# train_transforms = Compose([HSVAugment(), HorizontalFlip(p=0.5), LetterboxResize(target_size=640), Normalize()])\n",
        "# val_transforms = Compose([LetterboxResize(target_size=640), Normalize()])\n",
        "# train_ds = YOLODetectionDataset(root=cfg.root, split=cfg.train_split, transforms=train_transforms)\n",
        "# val_ds = YOLODetectionDataset(root=cfg.root, split=cfg.val_split, transforms=val_transforms)\n",
        "\n",
        "# QAT fine-tuning — must use precision=\"32-true\" (no AMP)\n",
        "# qat_lit_model = YoloNASLightningModule(model=qat_model, num_classes=cfg.num_classes, lr=2e-5, warmup_steps=50)\n",
        "# qat_data_module = DetectionDataModule(train_dataset=train_ds, val_dataset=val_ds, batch_size=8, num_workers=2)\n",
        "\n",
        "# qat_trainer = L.Trainer(\n",
        "#     max_epochs=5, accelerator=\"auto\",\n",
        "#     precision=\"32-true\",  # No AMP — fake-quant incompatible with autocast\n",
        "#     callbacks=[QATCallback(freeze_bn_after_epoch=3, freeze_observer_after_epoch=5)],\n",
        "#     default_root_dir=\"runs/qat\",\n",
        "# )\n",
        "# qat_trainer.fit(qat_lit_model, datamodule=qat_data_module)\n",
        "# print(\"QAT training complete!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert QAT model and export\n",
        "# qat_quantized = convert_quantized(qat_model)\n",
        "# qat_onnx_path = \"model_qat_int8.onnx\"\n",
        "# export_quantized_onnx(qat_quantized, qat_onnx_path, input_size=640)\n",
        "#\n",
        "# qat_size = Path(qat_onnx_path).stat().st_size / (1024 * 1024)\n",
        "# print(f\"QAT ONNX exported to: {qat_onnx_path}\")\n",
        "# print(f\"QAT model size: {qat_size:.1f} MB\")\n",
        "\n",
        "print(\"Uncomment the cells above after setting up your data and checkpoint paths.\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
