{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ONNX Runtime Inference\n",
        "\n",
        "This tutorial demonstrates how to run inference using an exported ONNX model with onnxruntime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "import matplotlib.pyplot as plt\n",
        "from modern_yolonas.inference.preprocess import preprocess\n",
        "from modern_yolonas.inference.postprocess import postprocess, rescale_boxes\n",
        "from modern_yolonas.inference.visualize import draw_detections, COCO_NAMES\n",
        "\n",
        "# Load ONNX model\n",
        "onnx_path = \"model_float32.onnx\"  # Update with your model path\n",
        "session = ort.InferenceSession(onnx_path)\n",
        "\n",
        "# Load a test image\n",
        "test_image_path = \"test.jpg\"  # Update with your image path\n",
        "original = cv2.imread(test_image_path)\n",
        "orig_h, orig_w = original.shape[:2]\n",
        "\n",
        "# Preprocess\n",
        "input_tensor, pad_info = preprocess(original, input_size=640)\n",
        "\n",
        "# Run inference\n",
        "pred_bboxes, pred_scores = session.run(None, {\"images\": input_tensor.numpy()})\n",
        "\n",
        "# Postprocess (NMS)\n",
        "boxes, scores, class_ids = postprocess(\n",
        "    torch.from_numpy(pred_bboxes),\n",
        "    torch.from_numpy(pred_scores),\n",
        "    conf_threshold=0.25,\n",
        "    iou_threshold=0.45,\n",
        ")\n",
        "\n",
        "# Rescale boxes to original image size\n",
        "if len(boxes) > 0:\n",
        "    boxes = rescale_boxes(boxes, pad_info, (orig_h, orig_w))\n",
        "\n",
        "print(f\"Detections: {len(boxes)}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize\n",
        "class_names = list(COCO_NAMES)  # Replace with your class names if custom-trained\n",
        "annotated = draw_detections(\n",
        "    original, boxes.numpy(), scores.numpy(), class_ids.numpy(),\n",
        "    class_names=class_names,\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"ONNX Runtime Inference ({len(boxes)} detections)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nDetections:\")\n",
        "for i in range(len(boxes)):\n",
        "    cls_name = class_names[int(class_ids[i])] if int(class_ids[i]) < len(class_names) else f\"class_{int(class_ids[i])}\"\n",
        "    print(f\"  {cls_name}: {scores[i]:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
